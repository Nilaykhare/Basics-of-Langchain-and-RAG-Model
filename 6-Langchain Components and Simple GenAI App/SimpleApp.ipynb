{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Simple Gen AI App Langchain",
   "id": "4f9d291a7e4bfcbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:04:58.385262Z",
     "start_time": "2025-08-16T10:04:58.357520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ],
   "id": "fba33a7ead84213c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Data Ingestion -- from the website we need to scrap the data",
   "id": "1694ad34ba6b97aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:09:12.906341Z",
     "start_time": "2025-08-16T10:09:12.902682Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain_community.document_loaders import WebBaseLoader",
   "id": "e826b6083b2328aa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:10:33.318711Z",
     "start_time": "2025-08-16T10:10:33.311691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw\")\n",
    "loader"
   ],
   "id": "d97305baa435a8fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x1b50a46bad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:11:24.481188Z",
     "start_time": "2025-08-16T10:11:24.409097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = loader.load()\n",
    "docs"
   ],
   "id": "ccf4fb650eb889af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\nGet started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic ‚Äî score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\\nLangSmith + LangChain OSSLangSmith is framework-agnostic ‚Äî\\xa0it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\\nFor more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\\nObservability\\u200b\\nObservability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\\nThis is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\\n\\nGet started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\nGet started by creating your first evaluation.\\nQuickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\\nAnalyze results of evaluations in the LangSmith UI and compare results over time.\\nEasily collect human feedback on your data to improve your application.\\n\\nPrompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\\n\\nGet started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityLangChain ForumTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.\\n\\n\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Steps-\n",
    "##### Load data ---> Docs ---> divide text into chunks (becasue everey LLMs have limitation to context size)---> Vectors --> vector embedding ---> vectorStore DB"
   ],
   "id": "ec39a3256b5d3e3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:20:32.608245Z",
     "start_time": "2025-08-16T10:20:32.577825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)\n",
    "documents"
   ],
   "id": "a0f2ca79455be295",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Skip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic ‚Äî score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content=\"LangSmith + LangChain OSSLangSmith is framework-agnostic ‚Äî\\xa0it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\\nFor more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\\nObservability\\u200b\\nObservability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\\nThis is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\"),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\nGet started by creating your first evaluation.\\nQuickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\\nAnalyze results of evaluations in the LangSmith UI and compare results over time.\\nEasily collect human feedback on your data to improve your application.\\n\\nPrompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityLangChain ForumTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Emedding",
   "id": "6b10e9579e1ae624"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:22:02.706959Z",
     "start_time": "2025-08-16T10:22:00.929137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings()"
   ],
   "id": "216c4c36664a92b8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:23:49.031288Z",
     "start_time": "2025-08-16T10:23:46.892087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorStoreDB = FAISS.from_documents(documents,embeddings)\n",
    "vectorStoreDB"
   ],
   "id": "c7d4aa0a3d4a698e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1b5231b8e90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Query from a vector DB",
   "id": "28f9fc535f5827ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:29:15.957279Z",
     "start_time": "2025-08-16T10:29:15.318836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"AI applications involve writing prompts to instruct \"\n",
    "result = vectorStoreDB.similarity_search(query)\n",
    "result[0].page_content"
   ],
   "id": "17974c8e592ecf3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\nGet started by creating your first evaluation.\\nQuickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\\nAnalyze results of evaluations in the LangSmith UI and compare results over time.\\nEasily collect human feedback on your data to improve your application.\\n\\nPrompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Retrieval chain, Document chain",
   "id": "c9e0c387838f9707"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:37:31.776592Z",
     "start_time": "2025-08-16T10:37:31.744037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o')"
   ],
   "id": "a2639f533c8f28fe",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:37:37.268856Z",
     "start_time": "2025-08-16T10:37:37.261009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\" \n",
    "    Answer the folowing question based only on the provided context:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm,prompt)"
   ],
   "id": "b760db869216c40f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:37:46.781214Z",
     "start_time": "2025-08-16T10:37:46.775887Z"
    }
   },
   "cell_type": "code",
   "source": "document_chain",
   "id": "3168adeeec283d06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\" \\n    Answer the folowing question based only on the provided context:\\n    <context>\\n    {context}\\n    </context>\\n\\n    '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001B52357BAD0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001B524800850>, root_client=<openai.OpenAI object at 0x000001B52357B890>, root_async_client=<openai.AsyncOpenAI object at 0x000001B5235884D0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:51:53.872495Z",
     "start_time": "2025-08-16T10:51:53.119101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\"input\":\"AI applications involve writing prompts to instruct \",\n",
    "                       \"context\": [Document(page_content=\"AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\")]\n",
    "                    })"
   ],
   "id": "4a7e22ecd0a2cc52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does LangSmith provide to assist with AI applications?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### However, we want the documents to first come from the retriever we just set up. That way, we can use the retriever to dynamically select the most relevant documents and pass those in for a given question.\n",
    "##### Input ----> Retriver ----> vectorStore DB"
   ],
   "id": "8ebb8122d65d0b51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:31:15.421821Z",
     "start_time": "2025-08-16T11:31:15.415687Z"
    }
   },
   "cell_type": "code",
   "source": "vectorStoreDB",
   "id": "ad9a06b9ff07c24a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1b5231b8e90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:38:15.006596Z",
     "start_time": "2025-08-16T11:38:15.001803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = vectorStoreDB.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever,document_chain)"
   ],
   "id": "ab778cf8b664d600",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:38:15.508910Z",
     "start_time": "2025-08-16T11:38:15.504645Z"
    }
   },
   "cell_type": "code",
   "source": "retrieval_chain\n",
   "id": "50d2c12dcbbeb824",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B5231B8E90>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\" \\n    Answer the folowing question based only on the provided context:\\n    <context>\\n    {context}\\n    </context>\\n\\n    '), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001B52357BAD0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001B524800850>, root_client=<openai.OpenAI object at 0x000001B52357B890>, root_async_client=<openai.AsyncOpenAI object at 0x000001B5235884D0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:40:16.443713Z",
     "start_time": "2025-08-16T11:40:14.966768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## get the response form the LLM\n",
    "response = retrieval_chain.invoke({\"input\":\"AI applications involve writing prompts to instruct \",\n",
    "                       \"context\": [Document(page_content=\"AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\")]\n",
    "                    })\n",
    "## get the response form the LLM\n",
    "response"
   ],
   "id": "380e9574fd90af01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'AI applications involve writing prompts to instruct ',\n",
       " 'context': [Document(id='621543ae-b978-42e1-8347-5676c3350e76', metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\nGet started by creating your first evaluation.\\nQuickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\\nAnalyze results of evaluations in the LangSmith UI and compare results over time.\\nEasily collect human feedback on your data to improve your application.\\n\\nPrompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.'),\n",
       "  Document(id='4ab8a72e-31dc-4f9d-bcca-47170c772a5d', metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityLangChain ForumTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.'),\n",
       "  Document(id='b75582f0-df33-4d1a-b04d-719a1be6086d', metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Skip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic ‚Äî score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.'),\n",
       "  Document(id='a8f827f7-f841-498a-882a-7bbf031b5d74', metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith')],\n",
       " 'answer': 'What benefits does the LangSmith platform offer for AI applications as per the provided context?'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:40:16.543021Z",
     "start_time": "2025-08-16T11:40:16.538551Z"
    }
   },
   "cell_type": "code",
   "source": "response['answer']",
   "id": "5592fd349dfedeca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What benefits does the LangSmith platform offer for AI applications as per the provided context?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T11:40:29.042864Z",
     "start_time": "2025-08-16T11:40:29.036661Z"
    }
   },
   "cell_type": "code",
   "source": "response['context']",
   "id": "e6a1a682ed27f2b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='621543ae-b978-42e1-8347-5676c3350e76', metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\nGet started by creating your first evaluation.\\nQuickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\\nAnalyze results of evaluations in the LangSmith UI and compare results over time.\\nEasily collect human feedback on your data to improve your application.\\n\\nPrompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.'),\n",
       " Document(id='4ab8a72e-31dc-4f9d-bcca-47170c772a5d', metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityLangChain ForumTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.'),\n",
       " Document(id='b75582f0-df33-4d1a-b04d-719a1be6086d', metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Skip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic ‚Äî score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.'),\n",
       " Document(id='a8f827f7-f841-498a-882a-7bbf031b5d74', metadata={'source': 'https://docs.smith.langchain.com/?_gl=1*1x0axhw*_gcl_au*MTYzOTI2MzQ3OC4xNzU0NjU0MDE2*_ga*MjExOTk5MTA2Ni4xNzU0NjU0MDE2*_ga_47WX3HKKY2*czE3NTUzMzg1ODQkbzgkZzEkdDE3NTUzMzkwMDkkajUyJGwwJGgw', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "521c095cb51fc5fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
