{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ],
   "id": "f6357a0191040fbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ],
   "id": "e4f77b251ee67e4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T10:06:38.691895Z",
     "start_time": "2025-08-14T10:06:38.685908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o')"
   ],
   "id": "fee5d9de2c695d76",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T10:06:40.523851Z",
     "start_time": "2025-08-14T10:06:40.519464Z"
    }
   },
   "cell_type": "code",
   "source": "print(llm)",
   "id": "7f1b0f6b77a558e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002D78707CFD0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002D78707D510> root_client=<openai.OpenAI object at 0x000002D78707CC50> root_async_client=<openai.AsyncOpenAI object at 0x000002D78707D2D0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T10:08:10.032330Z",
     "start_time": "2025-08-14T10:08:02.936581Z"
    }
   },
   "cell_type": "code",
   "source": "result = llm.invoke(\"What is Generative AI?\")",
   "id": "f0572ff69df72c1a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T10:08:20.472581Z",
     "start_time": "2025-08-14T10:08:20.469085Z"
    }
   },
   "cell_type": "code",
   "source": "print(result)",
   "id": "ea2613d6ece879c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a class of artificial intelligence models that can create or generate new data that resembles existing data. Unlike traditional AI models that are designed primarily for classification and prediction, generative AI models are capable of producing new content, such as images, music, text, or even complex simulations. \\n\\nSome of the key features and technologies involved in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** This is a popular architecture for generative models, introduced by Ian Goodfellow and others in 2014. It involves two neural networks, a generator and a discriminator, that are trained together. The generator creates new data instances, while the discriminator evaluates them. The goal is to have the generator create data that is indistinguishable from real data as assessed by the discriminator.\\n\\n2. **Variational Autoencoders (VAEs):** These are another type of generative model that learns to encode data into a lower-dimensional latent space and then decode it back, generating new data from this space.\\n\\n3. **Transformer Models:** Recently, transformer architectures such as OpenAI's GPT (Generative Pre-trained Transformer) have become prominent in the field of text generation. These models learn from vast amounts of text data and can generate human-like text based on the input they receive.\\n\\n4. **Diffusion Models:** These are probabilistic models designed for generating data by iteratively refining a noisy signal into a desired output. They have been used effectively for tasks like image synthesis.\\n\\nGenerative AI has wide-ranging applications including but not limited to: content creation for media and entertainment, data augmentation for training AI models, drug discovery by simulating molecular structures, enhancing creative processes, and even aiding in the design of products. It poses both exciting possibilities and challenges, such as the ethical implications of creating highly convincing fake media.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 372, 'prompt_tokens': 13, 'total_tokens': 385, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C4PAI1UXGQxsuyetW9NWKKRn04Os3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--684d4dff-5b1e-4623-8562-b1a5d40e43df-0' usage_metadata={'input_tokens': 13, 'output_tokens': 372, 'total_tokens': 385, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T10:08:38.424220Z",
     "start_time": "2025-08-14T10:08:38.419208Z"
    }
   },
   "cell_type": "code",
   "source": "type(result)",
   "id": "bdab536f5ebc94c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chatprompt Template",
   "id": "d3c1a561549ebca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:57:08.579888Z",
     "start_time": "2025-08-14T11:57:08.572976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ],
   "id": "a9aee270cb6e03eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:58:56.386452Z",
     "start_time": "2025-08-14T11:58:46.576511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\":\"Can you tell me about langsmith?\"})"
   ],
   "id": "aa5995496c9e0f0c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T11:59:05.326982Z",
     "start_time": "2025-08-14T11:59:05.322995Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "27cca28d8560bd6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a tool or platform associated with LangChain, a framework designed to build applications with large language models (LLMs). Launched in 2023, Langsmith focuses on enhancing the development and monitoring process for LLM applications. It offers a suite of features aimed at debugging, testing, and evaluating these applications to improve their performance and alignment with user requirements.\\n\\nSome key functionalities of Langsmith include:\\n\\n1. **Tracing and Debugging**: Langsmith provides in-depth tracing capabilities that allow developers to track how inputs are processed through the different components of an LLM-driven application. This helps in identifying inefficiencies or errors in the application's logic or data flow.\\n\\n2. **Testing Tools**: The platform offers robust testing frameworks to ensure that applications behave as expected. This includes testing against various scenarios to validate the outputs from an LLM against desired outcomes.\\n\\n3. **Evaluation Metrics**: Langsmith enables developers to set and analyze specific evaluation metrics. This helps in quantifying the performance of the application and identifying areas for improvement.\\n\\n4. **User Feedback Loop**: By capturing and integrating user feedback, Langsmith assists developers in continuously refining and optimizing their applications based on real-world usage and user interactions.\\n\\nOverall, Langsmith serves as a comprehensive environment for managing the complexities involved in deploying commercial-grade applications using large language models, thereby enhancing their reliability and efficacy.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 33, 'total_tokens': 307, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'id': 'chatcmpl-C4QtRjNLsKTJeRvm1nvIgLGJqpDwc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--6daee756-4a89-4aa7-96f6-5ba5ecccdf77-0' usage_metadata={'input_tokens': 33, 'output_tokens': 274, 'total_tokens': 307, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T12:00:40.558528Z",
     "start_time": "2025-08-14T12:00:40.553654Z"
    }
   },
   "cell_type": "code",
   "source": "type(response)",
   "id": "2572da5feae7a69a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T12:01:36.720592Z",
     "start_time": "2025-08-14T12:01:36.714007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser"
   ],
   "id": "241a218b5577eb8f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T12:01:58.243907Z",
     "start_time": "2025-08-14T12:01:54.768638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ],
   "id": "c53662df8251a585",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a tool and service developed by LangChain to help developers improve their AI applications. It focuses on tasks such as evaluating, monitoring, and debugging applications that utilize language models. By offering a platform for tracing and troubleshooting, LangSmith enables developers to better understand the behavior and performance of their models, ensuring they're working efficiently and effectively. The tool is especially useful for identifying and resolving issues that may arise in complex language-based systems, providing insights into how models process inputs and generate outputs.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e000036991c6bd7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "efcf29ad874f92c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
